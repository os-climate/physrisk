{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERAL WORKFLOW\n",
    "\n",
    "## Impact calculation process\n",
    "\n",
    "To calculate impacts for a specific asset, scenario, year, vulnerability model, and hazard, use the following function:\n",
    "`calculate_impacts(assets, hazard_model, vulnerability_model, scenario, year) -> Dict[ImpactKey, List[AssetImpactResult]]`\n",
    "\n",
    "### First part: calculating intensity curves\n",
    "(Calculate intensities and return periods for acute hazards, parameters, and definitions for chronic hazards)\n",
    "\n",
    "1. **Request Hazard Data**:\n",
    "\n",
    "   For each asset, generate requests for hazard data and obtain responses:\n",
    "\n",
    "   ```python\n",
    "   asset_requests, responses = _request_consolidated(hazard_model, model_asset, scenario, year)\n",
    "   ```\n",
    "\n",
    "   ```python\n",
    "   HazardDataRequest(self.hazard_type, asset.longitude, asset.latitude, scenario=scenario, year=year, indicator_id=self.indicator_id)\n",
    "   ```\n",
    "      responses are obtained from:\n",
    "\n",
    "   ```python\n",
    "      hazard_model.get_hazard_events(requests)\n",
    "   ```\n",
    "\n",
    "\n",
    "2. **Process Hazard Events**:\n",
    "\n",
    "   If hazards are acute (events) or chronic (parameters), the responses are processed differently:\n",
    "   Acute Hazards: Responses include periods, intensities, units, and paths.\n",
    "   Chronic Hazards: Responses include parameters, definitions, units, and paths.\n",
    "\n",
    "\n",
    "3. **Retrieve Data**:\n",
    "\n",
    "   For Acute Hazards:\n",
    "\n",
    "   ```python\n",
    "   hazard_data_provider = self.hazard_data_providers[hazard_type]\n",
    "   intensities, return_periods, units, path = hazard_data_provider.get_data(longitudes, latitudes, indicator_id, scenario, year, hint, buffer)\n",
    "   ```\n",
    "   For Chronic Hazards:\n",
    "\n",
    "   ```python\n",
    "   hazard_data_provider = self.hazard_data_providers[hazard_type]\n",
    "   parameters, definitions, units, path = hazard_data_provider.get_data(longitudes, latitudes, indicator_id, scenario, year, hint, buffer)\n",
    "   ```\n",
    "\n",
    "   ```python\n",
    "   get_data(self, longitudes: List[float], latitudes: List[float], *, indicator_id: str, scenario: str, year: int, hint: Optional[HazardDataHint] = None, buffer: Optional[int] = None)\n",
    "   ```\n",
    "\n",
    "   The ``get_data`` method retrieves hazard data for given coordinates.\n",
    "\n",
    "4. **Determine Data Path**:\n",
    "\n",
    "   Build the path for data retrieval:\n",
    "\n",
    "   ```python\n",
    "   path = self._get_source_path(indicator_id=indicator_id, scenario=scenario, year=year, hint=hint)\n",
    "   ```\n",
    "\n",
    "   get_source_path(SourcePath) provides the source path mappings.\n",
    "\n",
    "5. **Retrieve Curves**:\n",
    "\n",
    "   If buffer is None, use:\n",
    "\n",
    "   ```python\n",
    "   values, indices, units = self._reader.get_curves(path, longitudes, latitudes, self._interpolation)\n",
    "   ```\n",
    "\n",
    "   If buffer is specified (The ``buffer`` variable is used to specify an area of a given size, as indicated by this variable, instead of using a single point):\n",
    "\n",
    "   ```python\n",
    "   values, indices, units = self._reader.get_max_curves(\n",
    "      path,\n",
    "      [\n",
    "         (\n",
    "            Point(longitude, latitude)\n",
    "            if buffer == 0\n",
    "            else Point(longitude, latitude).buffer(\n",
    "               ZarrReader._get_equivalent_buffer_in_arc_degrees(latitude, buffer)\n",
    "            )\n",
    "         )\n",
    "         for longitude, latitude in zip(longitudes, latitudes)\n",
    "      ],\n",
    "      self._interpolation\n",
    "   )\n",
    "   ```\n",
    "\n",
    "6. **Data Retrieval Functions**:\n",
    "\n",
    "   ```python\n",
    "   get_curves(self, set_id, longitudes, latitudes, interpolation=\"floor\")\n",
    "   ```\n",
    "\n",
    "   Get Curves: Retrieves intensity curves for each coordinate pair. Returns intensity curves, return periods, and units.\n",
    "\n",
    "   First, it constructs the path used to select the corresponding data in the bucket. From this data, it extracts the transformation matrix, coordinate system, data units, and return periods or indices (``index_values``). Next, it converts the geographic coordinates to image coordinates. Then, it interpolates the data based on the specified interpolation method.\n",
    "\n",
    "   If the interpolation method is ``\"floor\"``, it converts ``image_coords`` to integer values using the floor function and adjusts coordinates for wrapping around the dataset dimensions. It retrieves the data values using ``z.get_coordinate_selection``, then reshapes and returns the data along with ``index_values`` and ``units``.\n",
    "\n",
    "   For other interpolation methods (``\"linear\"``, ``\"max\"``, ``\"min\"``), it calls ``_linear_interp_frac_coordinates`` to perform the specified interpolation. Finally, it returns the interpolated results along with ``index_values`` and ``units``.\n",
    "\n",
    "   ```python\n",
    "   get_max_curves(self, set_id, shapes, interpolation=\"floor\")\n",
    "   ```\n",
    "\n",
    "   Get Max Curves: Retrieves the maximum intensity curves for given geometries. Returns maximal intensity curves, return periods, and units.\n",
    "\n",
    "   First, it constructs the path used to locate the corresponding data in the bucket, similar to the ``get_curves`` method. From this data, it extracts the transformation matrix, coordinate system, data units, and index values (``index_values``). It then computes the inverse of the affine transformation matrix and applies it to the input geometries, transforming them into the coordinate system of the dataset.\n",
    "\n",
    "   Next, it generates a ``MultiPoint`` for each shape by creating a grid of points within the shape's bounding box and intersecting these points with the shape to retain only those points that lie within the shape. If the intersection of a shape with the grid points is empty, it falls back to using the centroid of the shape as a single point.\n",
    "\n",
    "   For the ``\"floor\"`` interpolation method, it converts the transformed coordinates to integer values using the floor method, retrieves the corresponding data values, and reshapes the data. For other interpolation methods (``\"linear\"``, ``\"max\"``, ``\"min\"``), it combines the transformed shapes with the multipoints and computes the fractional coordinates for interpolation.\n",
    "\n",
    "   Finally, it calculates the maximum intensity values for each shape by grouping the points corresponding to each shape and finding the maximum value for each return period. The method then returns the maximum intensity curves, return periods, and units.\n",
    "\n",
    "### Second part: applying a vulnerability model to obtain impacts\n",
    "\n",
    "When applying a chronic-type vulnerability model, the impact is calculated using the model's `get_impact` method. This method will return an `ImpactDistrib` object, which includes `impact_bins`, `impact_type`, `path`, and `prob` (i.e., it provides the impact distribution along with the hazard data used to infer it). This result is then stored in an `AssetImpactResult` object, together with the hazard_data (which consists of the intensity curves obtained previously). The `AssetImpactResult` is subsequently saved in the results dictionary, associated with an `ImpactKey` that comprises the `asset`, `hazard_type`, `scenario`, and `year`.\n",
    "\n",
    "On the other hand, for acute-type vulnerability models, the impact is calculated using the `get_impact_details` method of the model. This method returns an `ImpactDistrib` object, a `VulnerabilityDistrib` object (which includes `impact_bins`, `intensity_bins`, and `prob_matrix`), and a `HazardEventDistrib` object (which contains `intensity_bin_edges` and `prob`). In other words, it provides the impact distribution along with the vulnerability and hazard event distributions used to infer it. This information is stored in an `AssetImpactResult` object, which is then added to the results dictionary with an `ImpactKey`.\n",
    "\n",
    "## Risk measures calculation process\n",
    "\n",
    "To calculate risk measures for a specific asset, scenario, year, vulnerability model, and hazard, use the following function:\n",
    "`def calculate_risk_measures(self, assets: Sequence[Asset], prosp_scens: Sequence[str], years: Sequence[int]):`\n",
    "\n",
    "1. **Calculate all impacts**\n",
    "\n",
    "   First, using the `_calculate_all_impacts` method, the impacts for the specific hazard, asset, and vulnerability model are calculated for all the years and scenarios. This method uses `_calculate_single_impact`, which calculates each impact using the `calculate_impacts` method previously described.\n",
    "\n",
    "2. **Calculate risk measure**\n",
    "\n",
    "   For each asset, scenario, year, and hazard, the corresponding impact is used to determine the risk measures according to the selected calculation method.\n",
    "\n",
    "   The impact of the historical scenario is chosen as the `base impact`, and `risk measures` are calculated using the `calc_measure` function.\n",
    "\n",
    "   In the default use case, the `calc_measure` method defined in the `RealEstateToyRiskMeasures` class performs calculations differently depending on whether the hazard is chronic heat or another type. The difference between the two methods is that `calc_measure_cooling` uses `mean impacts` for calculations, while `calc_measure_acute` uses `exceedance curves`. In both cases, a `Measure` object is returned, which contains a `score` (REDFLAG, HIGH, MEDIUM, LOW), `measures_0` (future_loss), and a `definition`.\n",
    "\n",
    "   - **For cooling hazards**: It calculates the change in mean impact between historical and future scenarios. It assigns a risk score based on the future cooling levels and the change compared to predefined thresholds, returning a `Measure` object with the assigned score and future cooling value.\n",
    "   \n",
    "   - **For acute hazards**: It calculates the potential loss based on a 100-year return period by comparing historical and future loss values derived from exceedance curves. It assigns a risk score based on future loss levels and the change in loss relative to predefined thresholds, returning a `Measure` object with the assigned score and future loss value.\n",
    "\n",
    "   - **For the stress_test use case**: The `calc_measure` function in the `ThermalPowerPlantsRiskMeasures` class creates a `StressTestImpact` object to obtain the percentiles (norisk, p50, p75, p90), which are used to evaluate the impact based on its `mean_intensity`. This method also returns a `Measure` object with a `score` (HIGH, MEDIUM, LOW, NORISK, NODATA), `measures_0` (mean_intensity), and a `definition`.\n",
    "\n",
    "   - **For the generic use case**: In the `GenericScoreBasedRiskMeasures` class, the `calc_measure` method calculates risk scores differently based on whether the impact distribution is necessary or if underlying hazard data can be used instead. To generate the scores, bounds are defined for each hazard type.\n",
    "\n",
    "     - **When using hazard data**: It compares hazard parameters to the predefined threshold bounds. It returns a score based on the severity of the hazard, or NODATA if the parameter is invalid.\n",
    "   \n",
    "     - **Otherwise**: The method calculates two impact measures from historical and future data. It then determines the score category based on whether these measures fall within predefined ranges and returns a `Measure` object with the score and the first measure value.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
