from abc import abstractmethod
from collections import defaultdict
from dataclasses import dataclass
from typing import (
    Any,
    Dict,
    Iterable,
    Optional,
    Sequence,
    Set,
    Union,
)

import numpy as np
import pandas as pd
from pydantic import BaseModel, ConfigDict, Field
from physrisk.kernel.assets import Asset


class VulnerabilityConfigItem(BaseModel):
    """Item of vulnerability configuration."""

    model_config = ConfigDict(arbitrary_types_allowed=True)
    hazard_class: str = Field(
        "",
        description="Name of the physrisk hazard class.",
        examples=["RiverineInundation"],
    )
    asset_class: str = Field(
        "",
        description="Name of physrisk asset class.",
        examples=["Asset", "RealEstateAsset"],
    )
    asset_identifier: str = Field(
        "",
        description="Asset identifier in form of asset attribute " "key-value pairs.",
        examples=[
            "type=Buildings/Commercial,location=Europe",
            "occ_scheme=OED,occ_id=100",
        ],
    )
    indicator_id: str = Field(
        "", description="Hazard indicator identifier.", examples=["flood_depth"]
    )
    indicator_units: Optional[str] = Field(
        "", description="Hazard indicator units.", examples=["metres"]
    )
    impact_id: str = Field(
        "damage",
        description="Identifier for the impact type.",
        examples=["damage", "disruption"],
    )
    impact_units: Optional[str] = Field("", description="Units of the impact type.")
    curve_type: str = Field(
        "indicator/piecewise_linear",
        description="Type of the curve expressing the vulnerability function.",
        examples=["indicator/piecewise_linear", "threshold/piecewise_linear"],
    )
    points_x: Optional[Union[Sequence[float], np.ndarray]] = Field(
        None,
        description="Array of x (indicator/threshold) components of points defining vulnerability "
        "curve/surface.",
    )
    points_y: Union[Sequence[float], np.ndarray] = Field(
        [],
        description="Array of y (impact) components of points defining vulnerability curve/surface.",
    )
    points_z: Optional[Union[Sequence[float], np.ndarray]] = Field(
        None,
        description="Describes z (probability) components of points defining vulnerability "
        "curve/surface. 1 or 2 dimensional array.",
    )
    cap_of_points_x: Optional[float] = Field(
        None, description="Cap of x (indicator/threshold)."
    )
    cap_of_points_y: Optional[float] = Field(None, description="Cap of y (impact).")
    activation_of_points_x: Optional[float] = Field(
        None, description="Activation threshold of x (indicator/threshold)."
    )


def to_year_fraction_divisor(indicator_units: Optional[str]) -> float:
    if indicator_units is not None:
        if indicator_units == "days/year":
            return 365.0
        elif indicator_units == "weeks/year":
            return 52.0
        elif indicator_units == "months/year":
            return 12.0
    return 1.0


@dataclass
class DowntimeConfigItem:
    asset_class: str  # Name of physrisk asset class, e.g. 'RealEstateAsset'.
    asset_identifier: str  # Identifier of the asset, within the class, e.g. 'type=Buildings/Commercial,location=Europe'.
    points_x: Sequence[float]
    points_y: Sequence[float]


def convert_curve(key: str, value: Any):
    if key == "points_x" or key == "points_y" or key == "points_z":
        if isinstance(value, str):
            return [
                float(x) for x in value.replace("[", "").replace("]", "").split(",")
            ]
    if isinstance(value, float):
        if np.isnan(value):
            return None
    return value


def convert_row(row: Dict[Any, Any]):
    return {k: convert_curve(k, v) for k, v in row.items()}


def config_items_to_df(
    config_items: Sequence[Union[VulnerabilityConfigItem, DowntimeConfigItem]],
):
    return pd.DataFrame(vars(c) for c in config_items)


def config_items_to_csv(
    config_items: Sequence[Union[VulnerabilityConfigItem, DowntimeConfigItem]],
    path: str,
):
    df = config_items_to_df(config_items)
    df.to_csv(path, index=False)


def config_items_from_df(df: pd.DataFrame):
    if "hazard_class" in df.columns:
        return df.apply(VulnerabilityConfigItem)
    return df.apply(DowntimeConfigItem)


def config_items_from_csv(path: str):
    df = pd.read_csv(path)
    column = "hazard_class"
    if column in df.columns:
        residual_df = df[df[column].str.contains(",")]
        df = df[~df.index.isin(residual_df.index)]
        while 0 < len(residual_df):
            additional_df = residual_df.copy(deep=True)
            additional_df[column] = residual_df[column].apply(lambda x: x.split(",")[0])
            residual_df[column] = residual_df[column].apply(
                lambda x: ",".join(x.split(",")[1:])
            )
            residual_df = residual_df[residual_df[column] != ""]
            df = pd.concat([df, additional_df])
        return df.apply(lambda row: VulnerabilityConfigItem(**convert_row(row)), axis=1)
    else:
        return df.apply(lambda row: DowntimeConfigItem(**convert_row(row)), axis=1)


class ImpactCurveKey:
    def __init__(self, asset_identifier: str):
        self.identifier: Dict[str, str] = ImpactCurveKey.to_dict(asset_identifier)

    def __hash__(self):
        return hash(ImpactCurveKey.from_dict(self.identifier))

    def __eq__(self, other):
        if isinstance(other, ImpactCurveKey):
            return self.identifier.items() == other.identifier.items()
        return False

    def __ne__(self, other):
        return not self.__eq__(other)

    def __str__(self):
        return ImpactCurveKey.from_dict(self.identifier)

    @staticmethod
    def to_dict(identifier: str) -> Dict[str, str]:
        if 0 < len(identifier):
            my_dict = dict(key_value.split("=") for key_value in identifier.split(","))
            return dict(
                (key.lower(), value.upper())
                for (key, value) in sorted(my_dict.items())
                if value.upper() != "GENERIC"
            )
        else:
            return defaultdict()

    @staticmethod
    def from_dict(identifier: Dict[str, str]) -> str:
        return ",".join(
            ["=".join([key, str(value)]) for key, value in identifier.items()]
        )

    @staticmethod
    def get(asset: Asset, attributes: Set[str], keys: Optional[Iterable[Any]] = None):
        key = ImpactCurveKey(
            ImpactCurveKey.from_dict(
                {
                    attribute: getattr(asset, attribute)
                    for attribute in attributes
                    if hasattr(asset, attribute)
                }
            )
        )
        if keys is not None and key not in keys:
            for pattern in [["location"], ["type"], ["location", "type"]]:
                reduced_key = ImpactCurveKey(
                    ImpactCurveKey.from_dict(
                        {
                            key: value
                            for key, value in key.identifier.items()
                            if key not in pattern
                        }
                    )
                )
                if reduced_key in keys:
                    return reduced_key
            raise ValueError("Failed to map asset to an impact curve.")
        return key


class ImpactCurve:
    def __init__(
        self,
        curve_type: str,
        indicator_units: Optional[str],
        cap_of_points_x: Optional[float],
        cap_of_points_y: Optional[float],
        activation_of_points_x: Optional[float],
    ):
        assert curve_type in ["indicator", "threshold"]
        self.curve_type = curve_type
        self.indicator_units = indicator_units
        self.cap_of_points_x = cap_of_points_x
        self.cap_of_points_y = cap_of_points_y
        self.activation_of_points_x = activation_of_points_x

    @abstractmethod
    def get_impact(self, points_x: np.ndarray) -> np.ndarray: ...

    @staticmethod
    def get_impact_curve(item: VulnerabilityConfigItem):
        curve_type = item.curve_type.split("/")[0]
        cap_of_points_y = item.cap_of_points_y
        points_y = np.array(item.points_y)
        if item.points_x is None:
            assert len(item.points_y) == 1
            points_x = np.zeros(len(item.points_y))
        else:
            points_x = np.array(item.points_x)
        if item.curve_type.split("/")[-1] == "parametric":
            return ParametricImpactCurve(
                curve_type=curve_type,
                indicator_units=item.indicator_units,
                points_x=points_x,
                points_y=points_y,
                cap_of_points_x=item.cap_of_points_x,
                cap_of_points_y=cap_of_points_y,
                activation_of_points_x=item.activation_of_points_x,
            )
        return PiecewiseLinearImpactCurve(
            curve_type=curve_type,
            indicator_units=item.indicator_units,
            points_x=points_x,
            points_y=points_y,
            cap_of_points_x=item.cap_of_points_x,
            cap_of_points_y=cap_of_points_y,
            activation_of_points_x=item.activation_of_points_x,
        )


class PiecewiseLinearImpactCurve(ImpactCurve):
    def __init__(
        self,
        curve_type: str,
        indicator_units: Optional[str],
        points_x: np.ndarray,
        points_y: np.ndarray,
        cap_of_points_x: Optional[float],
        cap_of_points_y: Optional[float],
        activation_of_points_x: Optional[float],
    ):
        super().__init__(
            curve_type,
            indicator_units,
            cap_of_points_x,
            cap_of_points_y,
            activation_of_points_x,
        )
        self.points_x = points_x
        self.points_y = points_y

    def get_impact(self, points_x: np.ndarray) -> np.ndarray:
        if self.cap_of_points_x is not None:
            points_x[self.cap_of_points_x < points_x] = self.cap_of_points_x
        points_y = np.interp(points_x, self.points_x, self.points_y)
        if self.cap_of_points_y is not None:
            points_y[self.cap_of_points_y < points_y] = self.cap_of_points_y
        if self.activation_of_points_x is not None:
            points_y[points_x <= self.activation_of_points_x] = 0.0
        return points_y


class ParametricImpactCurve(ImpactCurve):
    def __init__(
        self,
        curve_type: str,
        indicator_units: Optional[str],
        points_x: np.ndarray,
        points_y: np.ndarray,
        cap_of_points_x: Optional[float],
        cap_of_points_y: Optional[float],
        activation_of_points_x: Optional[float],
    ):
        assert activation_of_points_x is not None
        assert cap_of_points_y is not None
        assert len(points_x) == 1
        assert len(points_y) == 1
        super().__init__(
            curve_type,
            indicator_units,
            cap_of_points_x,
            cap_of_points_y,
            activation_of_points_x,
        )
        if self.cap_of_points_y == 0.0:
            self.scale = 1.0
        else:
            self.scale = (points_x[0] - activation_of_points_x) / np.log(
                1.0 / (1.0 - (points_y[0] / self.cap_of_points_y))
            )

    def get_impact(self, points_x: np.ndarray) -> np.ndarray:
        if self.cap_of_points_x is not None:
            points_x[self.cap_of_points_x < points_x] = self.cap_of_points_x
        if self.cap_of_points_y is not None and self.activation_of_points_x is not None:
            return np.array(
                [
                    (
                        0.0
                        if point_x < self.activation_of_points_x
                        else self.cap_of_points_y
                        * (
                            1.0
                            - np.exp(
                                -(point_x - self.activation_of_points_x) / self.scale
                            )
                        )
                    )
                    for point_x in points_x
                ]
            )
        return np.zeros(len(points_x))
