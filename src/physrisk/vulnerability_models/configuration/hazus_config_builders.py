from pathlib import Path, PurePath
from typing import List, Optional, Sequence
from fsspec import AbstractFileSystem
import numpy as np
import pandas as pd
from pint import UnitRegistry
import s3fs

from physrisk.kernel.curve import add_x_value_to_curve
from physrisk.vulnerability_models.config_based_impact_curves import (
    VulnerabilityConfigItem,
)
from physrisk.vulnerability_models.configuration.config_builders import (
    ConfigBuilder,
    ConfigBuilderBase,
)

ureg = UnitRegistry()


def _download_inputs(filename: str, source_dir: Path):
    s3 = s3fs.S3FileSystem(anon=True)
    s3.download(
        str(PurePath("os-climate-physical-risk") / "vulnerability" / filename),
        str(source_dir / filename),
    )
    # or we can use boto3, e.g.:
    # s3_client = boto3.client(
    #    "s3",
    # )
    # with open(filename, 'wb') as f:
    #    s3_client.download_fileobj("os-climate-physical-risk", f"vulnerability/{filename}", f)


class ConfigBuilderHazusWind(ConfigBuilderBase, ConfigBuilder):
    def __init__(
        self,
        source_dir: Optional[Path] = None,
        fs: Optional[AbstractFileSystem] = None,
        attributes: Sequence[str] = ["hazus_wind_spec_build_type", "damage_type"],
    ):
        """Create config builder for extracting vulnerability config items from an extract of Hazus wind damage functions.
        Args:
            source_dir (Optional[Path], optional): Full path to directory containing any source files.
                Defaults to None, in which case the default on-boarding directory in the
                repo is used. Defaults to None.
            fs (Optional[AbstractFileSystem], optional): Instance of AbstractFileSystem to use to
                access source_dir e.g. S3FileSystem. Defaults to None, in which case a
                LocalFileSystem is assumed.
            attributes (Sequence[str], optional): Defaults to ["hazus_wind_spec_build_type", "damage_type"].Attributes can be:
                damage_type: can take values 'structure', 'contents' or 'downtime'
                hazus_wind_spec_build_type: the Hazus Specific Building Type
                hazus_terrain_id: the Hazus terrain ID
                If omitted, the curves average over the missing attribute. By default, we average the curves of different
                hazus_terrain_id.
        """
        super().__init__(source_dir=source_dir, fs=fs)
        self.attribues = attributes

    def build_config(self):
        """Create vulnerability config based on Hazus damage functions."""
        # we cache the dataframe for speed: takes over a minute to load from Excel
        #
        df = self.cached_dataframe()
        grouped_df = self._grouped_data_frame(df, groupby=list(self.attributes))
        config_items = self._config_items(grouped_df, attributes=list(self.attributes))
        return config_items

    def download_inputs(self):
        _download_inputs(
            "HazusWindDamFunctions_Hazus61.xlsx", self.source_dir / "wind_hazus"
        )

    def cached_dataframe(self):
        cached_df_path = (
            self.source_dir / "wind_hazus" / "HazusWindDamFunctions_Hazus61.csv"
        )
        if not cached_df_path.exists():
            df = self._load_data_frame()
            df.to_csv(cached_df_path)
        df = pd.read_csv(cached_df_path)
        return df

    def _config_items(
        self,
        df: pd.DataFrame,
        attributes: List[str] = ["hazus_wind_spec_build_type", "hazus_terrain_id"],
    ):
        units = "mph"
        df["points_y"] = df.apply(
            lambda row: [
                float(row[key]) for key in row.keys() if key.startswith("dmg_")
            ],
            result_type="reduce",
            axis=1,
        )
        if np.all(
            [
                column.endswith(units)
                for column in df.columns
                if column.startswith("dmg_")
            ]
        ):
            points_x = ureg.convert(
                np.array(
                    [
                        float(column[4 : -len(units)])
                        for column in df.columns
                        if column.startswith("dmg_")
                    ]
                ),
                units,
                "m/s",
            )
        hazard_class = "Wind"
        indicator_id = "max_speed"
        indicator_units = "m/s"
        impact_id = "damage"

        def asset_identifier(row):
            return ",".join([a + "=" + str(row[a]) for a in attributes])

        config_items = list(
            df.apply(
                lambda row: VulnerabilityConfigItem(
                    hazard_class=hazard_class,
                    asset_class="Asset",
                    asset_identifier=asset_identifier(row),
                    indicator_id=indicator_id,
                    indicator_units=indicator_units,
                    impact_id=impact_id,
                    impact_units=None,
                    curve_type="indicator/piecewise_linear",
                    points_x=points_x,
                    points_y=[
                        float(row[key]) for key in row.keys() if key.startswith("dmg_")
                    ],
                    points_z=None,
                    cap_of_points_x=None,
                    cap_of_points_y=None,
                    activation_of_points_x=None,
                ),
                axis=1,
            ).values
        )
        return config_items

    def _grouped_data_frame(
        self,
        df: pd.DataFrame,
        groupby: List[str] = [
            "hazus_wind_spec_build_type",
            "damage_type",
            "hazus_terrain_id",
        ],
    ):
        df_group = df.groupby(groupby).mean().reset_index()
        df_group = df_group.apply(
            lambda row: (
                {
                    key: row[key] / 360.0 if key.upper().startswith("WS") else row[key]
                    for key in row.index
                }
                if row["damage_type"] == "downtime"
                else row
            ),
            axis=1,
        )
        df_group = df_group.rename(
            columns={
                column: "dmg_" + column[2:] + "mph"
                for column in df_group.columns
                if column.upper().startswith("WS")
            }
        )
        return df_group

    def _load_data_frame(self):
        file_path = (
            self.source_dir / "wind_hazus" / "HazusWindDamFunctions_Hazus61.xlsx"
        )
        # wind building types
        # huListOfWindBldgTypes gives for each Specific Building Type (SBT)
        # a number of Wind Building Characteristics (WBC)
        # the combination of SBT and WBC set has a unique ID 'wbID'
        wbt_df = pd.read_excel(io=str(file_path), sheet_name="huListOfWindBldgTypes")
        wbt_df = wbt_df.rename(columns={"sbtName": "hazus_wind_spec_build_type"})

        # curves are available for combinations of wbID, TERRAINID and
        # DamLossDescID
        # we are interested in the DamLossDescID that correspond to Building, Content
        # and LossOfUse
        damage_df = pd.read_excel(
            io=str(file_path), sheet_name="huDamLossFunDescription"
        )
        damage_df = damage_df.rename(columns={"DamLossClass": "damage_type"})
        damage_df["damage_type"] = damage_df["damage_type"].apply(
            lambda x: x.replace(" ", "").replace("\t", "")
        )

        # the curves are in huDamLossFun
        df = pd.read_excel(io=str(file_path), sheet_name="huDamLossFun")
        df = df.merge(damage_df, on="DamLossDescID", how="left")
        df = df[df["damage_type"].isin(["Building", "Content", "LossOfUse"])]
        df = df.merge(wbt_df, on="wbID", how="left")
        df = df.rename(columns={"TERRAINID": "hazus_terrain_id"})
        df = df[
            ["hazus_wind_spec_build_type", "damage_type", "hazus_terrain_id"]
            + [column for column in df.columns if column.upper().startswith("WS")]
        ]
        df["damage_type"] = df["damage_type"].apply(
            lambda key: (
                "structure"
                if key.lower() == "building"
                else ("contents" if key.lower() == "content" else "downtime")
            )
        )
        # we return a data frame with the curves for
        # hazus_wind_spec_build_type: the Specific Buuilding Type
        # damage_type: 'structure', 'contents' or 'downtime
        # hazus_terrain_id
        return df

    # def _occupancy_sbt_blend(self):
    #     file_path = (
    #         self.source_dir / "wind_hazus" / "HazusWindDamFunctions_Hazus61.xlsx"
    #     )
    #     # wind building types
    #     wbt_df = pd.read_excel(io=str(file_path), sheet_name="huListOfWindBldgTypes")

    # def _sbt_weights(self):
    #     file_path = self.source_dir / "wind_hazus" / "HazusWindDamFunctions_Hazus61.xlsx"
    #     wbt_df = pd.read_excel(io=str(file_path), sheet_name="huGBSMapping")
    #     col_mapping = {col: col[:-1] for col in wbt_df.columns if col.endswith("p")}
    #     df_renamed = wbt_df.rename(columns=col_mapping)
    #     sbts = list(col_mapping.values())
    #     sbt_weights = df_renamed.groupby(["Occupancy"])[sbts].mean()
    #     return sbt_weights[sbts].sum(axis=1)


class ConfigBuilderHazusFlood(ConfigBuilderBase, ConfigBuilder):
    def __init__(
        self,
        source_dir: Optional[Path] = None,
        fs: Optional[AbstractFileSystem] = None,
        adjust_to_absolute_depth: bool = True,
        flood_depth_threshold: float = 0.05,
        first_floor_height: float = 0.3,
    ):
        """Create config builder for generating vulnerability config items from an extract of Hazus flood damage
        functions.

        There is a point of attention around the use of Hazus flood damage functions. The functions provide damage
        for negative flood depths. This is because the functions are based on flood depth relative to the height
        of the first finished floor. The difference is material in cases where the first finished floor is elevated,
        perhaps with a crawl space or basement underneath. The correct way of applying the functions is to calculate
        a relative depth, $d_r$ which is the difference between the absolute flood depth $d_a$ and the height
        of the first finished floor above grade, $d_f$.

        $d_r = d_a - d_f$

        It can also be important to use a minimum relative absolute depth threshold, $d_t$ in applying the
        function. To illustrate this, say the finished floor is 1 m above grade and the absolute flood depth
        is 0 m. Some curves have non-zero damage at -4 feet (-1.22 m) flood depth. Since $d_r$ is -1.0 m,
        we would see a non-zero damage. To avoid this a threshold, $d_t$ can be added to the absolute
        flood depth, below which the damage is considered to be zero:

        if $d_a < d_t$ then damage is zero, otherwise damage is $v(d_r)$, $v$ being the Hazus damage function.

        It may be desirable to apply this logic in code, as part of the vulnerability model, so that the calculation
        can react to asset-specific information. On the other hand, it may be desirable to calculate a function
        based on absolute flood depth, for example for use in a sectorial approach.

        If adjust_to_absolute_depth is set to False, the curves will be returned as a function of relative depth:
        the same convention as Hazus. Otherwise, the curves will be adjusted to be functions of absolute depth
        using the min_flood_depth and first_floor_height parameters provided. A limitation is noted that these
        parameters are used across all curves, although clearly some Hazus curves are relevant in the case that a
        basement is present: in general a more sophisticated approach is needed to adjust _all_ curves.


        Args:
            source_dir (Optional[Path], optional): Full path to directory containing any source files.
                Defaults to None, in which case the default on-boarding directory in the
                repo is used. Defaults to None.
            fs (Optional[AbstractFileSystem], optional): Instance of AbstractFileSystem to use to
                access source_dir e.g. S3FileSystem. Defaults to None, in which case a
                LocalFileSystem is assumed.
            adjust_to_absolute_depth (bool, optional): If True, the curves will be adjusted to be functions of absolute
                flood depth, using the min_flood_depth and first_floor_height parameters provided. Defaults to True.
            flood_depth_threshold (float, optional): Minimum flood depth in metres below which the damage is considered
            to be zero, used when adjust_to_absolute_depth is True.
            Defaults to 0.05 m (5 cm).
            first_floor_height (float, optional): First floor height in metres above grade, used when
            adjust_to_absolute_depth is True. The default of 0.3 m corresponds to a slab foundation.
        """
        super().__init__(source_dir=source_dir, fs=fs)
        self.adjust_to_absolute_depth = adjust_to_absolute_depth
        self.flood_depth_threshold = flood_depth_threshold
        self.first_floor_height = first_floor_height

    def build_config(self):
        """Create vulnerability config based on Hazus damage functions."""
        # some processing done at using pandas:
        df = self._load_data_frame()
        return self._config_items(df)

    def download_inputs(self):
        _download_inputs(
            "HazusFloodDamageFunctions_Hazus61.xlsx",
            self.source_dir / "inundation_hazus",
        )

    def _config_items(self, df: pd.DataFrame):
        hazard_class = "CoastalInundation,PluvialInundation,RiverineInundation"
        indicator_id = "flood_depth"
        indicator_units = "metres"
        impact_id = "damage"

        def asset_identifier(row):
            damage_type = row["damage_type"]
            dmg_id = row["hazus_fl_dmg_id"].split("_")[1]
            return f"hazus_fl_{damage_type}_dmg_id={dmg_id}"

        config_items: Sequence[VulnerabilityConfigItem] = list(
            df.apply(
                lambda row: VulnerabilityConfigItem(
                    hazard_class=hazard_class,
                    asset_class="Asset",
                    asset_identifier=asset_identifier(row),
                    indicator_id=indicator_id,
                    indicator_units=indicator_units,
                    impact_id=impact_id,
                    impact_units=None,
                    curve_type="indicator/piecewise_linear",
                    points_x=np.round(
                        ureg.convert(np.array(row["points_x"]), "ft", "m"), 4
                    ),
                    points_y=np.array(row["points_y"]),
                    points_z=None,
                    cap_of_points_x=None,
                    cap_of_points_y=None,
                    activation_of_points_x=None,
                ),
                axis=1,
            ).values
        )
        if self.adjust_to_absolute_depth:
            for item in config_items:
                assert item.points_x is not None
                # convert to absolute and add the threshold point
                x, y, i = add_x_value_to_curve(
                    self.flood_depth_threshold,
                    np.array(item.points_x) + self.first_floor_height,
                    item.points_y,
                )
                # add the zero point in
                x, y = np.insert(x[i:], 0, 0.0), np.insert(y[i:], 0, 0.0)
                item.points_x = x
                item.points_y = np.round(y, 2)

        return config_items

    def _load_data_frame(self):
        hazus_path = (
            self.source_dir
            / "inundation_hazus"
            / "HazusFloodDamageFunctions_Hazus61.xlsx"
        )
        flood_df = pd.DataFrame(
            columns=["hazus_fl_dmg_id", "damage_type", "points_x", "points_y"]
        )
        if hazus_path.exists():
            hazus_file = pd.ExcelFile(hazus_path)
            sheet_names = [
                sn
                for sn in hazus_file.sheet_names
                if sn.startswith("flBldg")
                and (sn.endswith("DmgFn") or sn.endswith("DmgFunc"))
            ]
            for sheet_name in sheet_names:
                df = pd.read_excel(io=str(hazus_path), sheet_name=sheet_name)
                df["points_y"] = df.apply(
                    lambda row: [
                        float(row[key]) / 100.0
                        for key in row.keys()
                        if key.startswith("ft")
                    ],
                    result_type="reduce",
                    axis=1,
                )
                points_x = [
                    -float(column[2:-1]) if column.endswith("m") else float(column[2:])
                    for column in df.columns
                    if column.startswith("ft")
                ]
                df["points_x"] = df["points_y"].apply(
                    lambda _, points_x=points_x: points_x
                )
                assert (
                    len(
                        [
                            column
                            for column in df.columns
                            if column.lower().endswith("dmgfnid")
                        ]
                    )
                    == 1
                )
                column = [
                    column
                    for column in df.columns
                    if column.lower().endswith("dmgfnid")
                ][0]
                key = column[: -len("dmgfnid")].upper()
                if key == "BLDG":
                    key = "structure"
                elif key == "CONT":
                    key = "contents"
                elif key == "INV":
                    key = "inventory"
                assert key in ["structure", "contents", "inventory"]
                df["hazus_fl_dmg_id"] = df[column].apply(
                    lambda id, key=key: key
                    + "_"
                    + str(
                        id
                    )  # note that the key prefix is to emphasize that the hazus_fl_dmg_id
                    # is different for the different damage types.
                )
                df["damage_type"] = key
                df = df[["hazus_fl_dmg_id", "damage_type", "points_x", "points_y"]]
                flood_df = pd.concat(
                    [
                        flood_df[
                            ~flood_df["hazus_fl_dmg_id"].isin(df["hazus_fl_dmg_id"])
                        ],
                        df,
                    ]
                )
            return flood_df
        else:
            raise FileNotFoundError(
                f"Hazus flood data file not found at {hazus_path}. "
                "Please download the file and place it in the correct directory."
            )
